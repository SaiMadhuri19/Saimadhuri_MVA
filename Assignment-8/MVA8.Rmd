---
title: "MVA8"
author: "Sai Madhuri"
date: "2024-04-19"
output: html_document
---
#DATASET :The Auto MPG dataset contains information about various car models and their fuel efficiency. It includes attributes such as cylinders, displacement, horsepower, weight, acceleration, model year, and origin. 
#1.mpg: Miles per gallon, the target variable representing fuel efficiency.
#2.cylinders: Number of cylinders in the engine (typically 4, 6, or 8).
#3.displacement: Engine displacement in cubic inches.
#4.horsepower: Engine horsepower.
#5.weight: Vehicle weight in pounds.
#6.acceleration: Time taken for the vehicle to accelerate from 0 to 60 miles per hour (mph).
#7.model year: Year of manufacturing (e.g., 70 for 1970, 71 for 1971, etc.).
#8.origin: Origin of the car (1 for American, 2 for European, 3 for Japanese).
#9.car name: Name of the car model.

```{r}

file_path <- "/Users/user/Downloads/auto-mpg.csv"
data <- read.csv(file_path)
autompg <- read.csv("/Users/user/Downloads/auto-mpg.csv")
str(autompg)
```

```{r}
autompg <- read.csv("/Users/user/Downloads/auto-mpg.csv")
autompg$horsepower <- as.integer(autompg$horsepower)
cleaned_auto <- na.omit(autompg)
str(autompg)
```
```{r}
#Load required Libraries
library(dplyr)
library(tidyr)
library(MASS)
```




# Logistic Regression Analysis

### 1.Model Development
```{r}
# Create binary outcome variable: high mpg (1) vs. low mpg (0)
autompg <- autompg %>%
  mutate(new_mpg = ifelse(mpg > median(mpg), 1, 0))
```

```{r}
# Performing logistic regression on the dataset
logistic_simple <- glm(new_mpg ~ cylinders + displacement + horsepower + weight + acceleration, data = autompg, family = binomial)

```
#Considering the dependent variable mpg in binary format new_mpg and building the model with the independent variables namely cylinders,displacement,horsepower,weight and acceleration.


### 2.Model Acceptance
```{r}
summary(logistic_simple)
```

#The estimate column gives the coefficients that represent the log odds of the outcome variable (new_mpg) for one-unit increase in the predictor variable, holding other variables constant.

#For example: The coefficient for horsepower(-0.05) indicates the change in the outcome variable(new_mpg) for one unit increase in horsepower, holding other variables constant. And from the above it is evident that horsepower is the only one variable which is statistically significant. Other variables may not have a significant effect on mpg.

#The null deviance (543.43) represents the deviance when only the intercept is included in the model.

#The residual deviance (206.80) represents the deviance after fitting the logistic regression model with the predictor variables. Here the model is moderately acceptable.Generally,Smaller residual deviance indicates good fit.



### 3.Residual Analysis
```{r}
residuals(logistic_simple)
```
```{r}
plot(logistic_simple, which = 1)
```

#There is a fixed pattern in the residuals vs fitted plot which means that the selected independent variables will not explain the dependent variable well.

### 4.Prediction

```{r}
# Make predictions on the same dataset
predicted_values <- predict(logistic_simple, type = "response")
```


```{r}
# Convert predicted probabilities to binary predictions (0 or 1) based on a threshold 0.5
predicted_class <- ifelse(predicted_values > 0.5, 1, 0)
predicted_class
```

### 5.Accuracy

#we can compute accuracy by comparing predicted values with the original data

```{r}
original <- autompg$new_mpg  # Assuming new_mpg contains binary response variable (0 or 1)
accuracy <- mean(predicted_class == original)
print(accuracy)


```


#Accuracy Provides an overall measure of model performance. An accuracy of 0.716 indicates that the logistic regression model correctly predicted the outcome (the value of new_mpg) approximately 71.6% correctly.


### Visualizations
```{r}
# Install pROC package (only need to run once)
#install.packages("pROC")

# Load the pROC package
library(pROC)
```
```{r}
autompg$new_mpg
```
```{r}
length(autompg$new_mpg)
length(predicted_class)
```


```{r}
common <- intersect(seq_along(original), seq_along(predicted_class))
```


```{r}
# Compute ROC curve for the logistic regression model
roc_curve <- roc(original[common], predicted_class[common])

# Plot ROC curve
plot(roc_curve, legacy.axes = TRUE, main = "ROC Curve for Logistic Regression Model")
```


```{r}
roc(original[common],predicted_class[common],plot=TRUE, legacy.axes=TRUE, xlab="False Positive Percentage", ylab="True Postive Percentage", col="#377eb8", lwd=4, percent=TRUE, print.auc=TRUE, partial.auc=c(100, 90), auc.polygon = TRUE, auc.polygon.col = "#377eb822", print.auc.x=45)
```


#ROC curves are typically used to evaluate the performance of binary classification models, where the predicted classes represent binary outcomes (e.g., positive/negative, yes/no). Since the auto-mpg dataset involves predicting a continuous outcome (mpg), using a ROC curve isn't appropriate.





