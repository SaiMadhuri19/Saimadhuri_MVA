---
title: "Socialmedia"
author: "Sai Madhuri"
date: "2024-03-24"
output: html_document
---

```{r}
library(readxl)
sm <- read_excel("/Users/user/Downloads/social_media_cleaned.xlsx")
str(sm)
```


```{r}
sm1 <- sm[, 2:9]
sm1

```

```{r}
#load necessary libraries
library(magrittr)
library(NbClust)
library(cluster)
library(factoextra)
```
# Cluster Analysis
```{r}
#Hierarchical Clustering- Dendrogram
sm_scaled <- scale(sm1)
dist_matrix <- dist(sm_scaled)

#Clustering Single
hc <- hclust(dist_matrix,method = "single")
fviz_dend(hc)

```
```{r}
#Default Clustering

hc <- hclust(dist_matrix)
plot(hc, hang = -1, cex = 0.6, main = "Dendrogram for Hierarchical Clustering")

```
```{r}
#Average Clustering

hc <- hclust(dist_matrix,method = "average")
plot(hc, hang = -1, cex = 0.6, main = "Dendrogram for Hierarchical Clustering")

```

#By observing the above dendrogram's k=2 clusters will be sufficient.This is confirmed further with D index graphical representation.


```{r}
num_clusters <- 2
clusters <- cutree(hc, k = num_clusters)

# Membership for each cluster
table(clusters)

```

```{r}

# Principal Components
pca_result <- prcomp(sm1,scale=TRUE)
pca_result


```
```{r}
#Non-Hierarchical Clustering(k-means)
num_clusters <- 2
kmeans_model <- kmeans(sm1, centers = num_clusters)

# Membership for each cluster
table(kmeans_model$cluster)
```

```{r}
# Visualize cluster and membership using first two Principal Components
fviz_cluster(list(data = pca_result$x[, 1:2], cluster = kmeans_model$cluster))
```

```{r}
# Visualize cluster centers for k-means
fviz_cluster(kmeans_model, data = sm_scaled, geom = "point", frame.type = "convex", 
             pointsize = 2, fill = "white", main = "K-means Cluster Centers")
```

```{r}
# Visualize cluster and membership using first two Principal Components for k-means
pca_result <- prcomp(sm_scaled, scale = TRUE)
fviz_cluster(kmeans_model, data = pca_result$x[, 1:2], geom = "point", 
             pointsize = 2, fill = "white", main = "K-means Clustering Result (PCA)")
```

```{r}
# Calculate silhouette information for k-means clustering
sil <- silhouette(kmeans_model$cluster, dist(sm_scaled))

# Visualize the silhouette plot for k-means clustering
fviz_silhouette(sil, main = "Silhouette Plot for K-means Clustering")
```

```{r}
#optimal cluster method/visualization
res.nbclust <- sm1 %>% scale() %>% NbClust(distance = "euclidean", min.nc = 2, max.nc = 10, method = "complete", index ="all") 
```

#From cluster analysis I am able to recognize users whose social media usage patterns are similar to mine.

# PCA

```{r}
#Get the correlations between the variables 

cor(sm1, use = "complete.obs")
```
```{r}
#Computing Principal Components
social_pca <- prcomp(sm1,scale=TRUE)
social_pca

```

```{r}
summary(social_pca)
```
```{r}
eigen_social<- social_pca$sdev^2
eigen_social
```

#From PCA variate representation of each PC, It's evident that PC1 and PC2 add arround 50% of the to total variance.

#Screeplot
```{r}
plot(eigen_social, xlab = "Component number", ylab = "Component variance", type = "l", main = "Scree diagram")
```
```{r}
plot(log(eigen_social), xlab = "Component number", ylab = "Component variance", type = "l", main = "Scree diagram")
```
```{r}
library(FactoMineR)
res.pca <- PCA(sm_scaled, graph = FALSE)
fviz_eig(res.pca, addlabels = TRUE)

```

###From the screeplot elbow it is benefial to consider PC1,PC2,PC3,PC4,PC5,PC6 as it covers 93% of total variance.

#Visualization using PC's
```{r}
library(FactoMineR)
library("factoextra")
res.pca <- PCA(sm1, graph = FALSE)
fviz_pca_var(res.pca, col.var = "black")
```

#From the above I can tell that most of my classmates usage timings of the apps  Instagram,Whatsapp/Wechat, LinkedIn, Youtube and snapchat are similar. Most probably, twitter and reddit are not used by me and my classmates.



# Factor Analysis

```{r}
# load library for factor analysis
library(ggplot2)
library(psych)

```

#Decide how many Factors are ideal for your dataset?
```{r}
fa.parallel(sm1)
```
#Parallel analysis suggests that the number of factors =  0  and the number of components =  0


#Explain the output for your factor model?
```{r}
fit.pc <- principal(sm1, nfactors=2, rotate="varimax")
fit.pc
```

#High absolute values (close to 1) indicate a strong relationship between the variable and the factor.
#h2 explains how much variance of the variables are explained by the factors.
#u2 indicates the amount of variance not explained by the factors
Principal Components Analysis
Call: principal(r = sm1, nfactors = 2, rotate = "varimax")
Standardized loadings (pattern matrix) based upon correlation matrix

                       RC1  RC2
SS loadings           2.27 1.80
Proportion Var        0.25 0.20
Cumulative Var        0.25 0.45
Proportion Explained  0.56 0.44
Cumulative Proportion 0.56 1.00

Mean item complexity =  1.3
Test of the hypothesis that 2 components are sufficient.

The root mean square of the residuals (RMSR) is  0.14 
 with the empirical chi square  29.01  with prob <  0.066 
 

```{r}
round(fit.pc$values, 3)
```


```{r}
fit.pc$loadings
```
```{r}
# Communalities
fit.pc$communality

```
```{r}
# Rotated factor scores, Notice the columns ordering: RC1, RC2
fit.pc
fit.pc$scores

```
```{r}
fa.plot(fit.pc) # See Correlations within Factors

```
Show the columns that go into each factor?
```{r}
fa.diagram(fit.pc) # Visualize the relationship

```


Perform some visualizations using the factors

```{r}
#very simple structure visualization
vss(sm1)

```
Very Simple Structure
Call: vss(x = sm1)
VSS complexity 1 achieves a maximimum of 0.61  with  6  factors
VSS complexity 2 achieves a maximimum of 0.78  with  7  factors

The Velicer MAP achieves a minimum of 0.06  with  1  factors 
BIC achieves a minimum of  -53.17  with  1  factors
Sample Size adjusted BIC achieves a minimum of  1.47  with  5  factors

Statistics by number of factors 

```{r}
# Computing Correlation Matrix
corrm.social <- cor(sm1)
corrm.social

```
```{r}
plot(corrm.social)

```
```{r}
social_pca <- prcomp(sm1, scale=TRUE)
summary(social_pca)

```


```{r}
plot(social_pca)

```


#Biplot Visualization
```{r}
biplot(fit.pc)

```



#I feel factor analysis is not beneficial for the social media data because I observed that we are missing the most part of the uniqueness of these apps by including factors and we are able to capture only a small portion of variances by using factors.
#And parallel analysis screeplot indicated that the ideal number of factors for the social media data is zero.
#From the component analysis we got similar results to PCA, where the apps like Instagram, whatsapp/wechat, LinkedIn, Youtube, Snapchat usages are a bit similar and high compared to OTT, Twitter and Reddit.


* Key takeaways from my analysis
  * Interestingly I found users having same pattern social media usage as mine are not more energetic the entire week like me.(3/5). This suggests that we need to reduce our social media usage to become more productive.
  * Instagram, Whatsapp/Wechat, LinkedIn, Youtube, Snapchat are the most popular apps used by the students.
  


